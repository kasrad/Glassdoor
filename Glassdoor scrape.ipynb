{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glassdoor scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via this script I aim to scrape reported salaries from glassdoor for a specific role in a specific city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test - Android Developer Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggest\\\n",
    "Chosen=false&clickSource=searchBtn&typedKeyword=\\\n",
    "Android+Developer&sc.keyword=Android+Developer&locT=C&locId=1154532&jobType='\n",
    "headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36' }\n",
    "data=bytes(json.dumps(headers), encoding=\"utf-8\")\n",
    "req = urllib.request.Request(url, data, headers)\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    the_page = response.read()\n",
    "print(urllib.request.urlopen(req))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(the_page, 'html.parser')\n",
    "soup.find_all(\"i\", class_=\"info infoSalEst margLtSm\")\n",
    "tag = soup.find_all(attrs={\"data-displayed-max-salary\": True})\n",
    "\n",
    "min_sal = np.zeros(0)\n",
    "for obj in soup.find_all('i', class_=\"info infoSalEst margLtSm\"):\n",
    "    print(obj.get(\"data-displayed-min-salary\"))\n",
    "    min_sal = np.append(min_sal,float(obj.get(\"data-displayed-min-salary\")))\n",
    "\n",
    "print(min_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(min_sal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unfortunately, glassdoor.com does not report estimated salaries for all roles, therefore we need to scrape the 'Salaries' section of Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Scientist London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jupyterthemes.jtplot as jtplot\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#specify URL - should be automated\n",
    "url = 'https://www.glassdoor.co.uk/Salaries/london-data-scientist-salary-SRCH_IL.\\\n",
    "0,6_IM1035_KO7,21.htm'\n",
    "\n",
    "#standard python user agent is blocked\n",
    "headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36' }\n",
    "data=bytes(json.dumps(headers), encoding=\"utf-8\")\n",
    "req = urllib.request.Request(url, data, headers)\n",
    "with urllib.request.urlopen(req) as response:\n",
    "    the_page = response.read()\n",
    "print(urllib.request.urlopen(req))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use beatiful soup for parsing\n",
    "soup = BeautifulSoup(the_page, 'html.parser')\n",
    "\n",
    "#obtain min and max salaries\n",
    "min_sal = np.zeros(0)\n",
    "max_sal = np.zeros(0)\n",
    "for obj in soup.find_all(\"div\", class_=\"JobInfoStyle__range formFactorHelpers__showHH\"):\n",
    "    min_sal = np.append(min_sal, obj.text[8:10])\n",
    "    max_sal = np.append(max_sal, obj.text[15:17])\n",
    "\n",
    "# for maxobj in soup.find_all(\"div\", class_=\"minor cell alignRt maxPay\"):\n",
    "#      max_sal = np.append(max_sal, maxobj.text[15:17])\n",
    "\n",
    "# #convert into numbers\n",
    "# min_sal = np.char.replace(min_sal, 'k', '000')\n",
    "# min_sal = np.char.replace(min_sal, '£', '')\n",
    "# max_sal = np.char.replace(max_sal, 'k', '000')\n",
    "# max_sal = np.char.replace(max_sal, '£', '')\n",
    "\n",
    "min_sal = min_sal.astype(int)\n",
    "max_sal = max_sal.astype(int)\n",
    "     \n",
    "salaries = np.zeros((min_sal.shape[0], 3))\n",
    "salaries[:,0] = min_sal\n",
    "salaries[:,1] = max_sal\n",
    "salaries = salaries[salaries[:, 0].argsort()]\n",
    "salaries[:,2] = range(max_sal.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capgemini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dunnhumby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elsevier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imagini Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barclays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J Sainsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unilever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virgin Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zopa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Department for Work And Pensions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HSBC Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Capita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Deutsche Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0\n",
       "0                          Capgemini\n",
       "1                          Dunnhumby\n",
       "2                           Elsevier\n",
       "3                   Imagini Holdings\n",
       "4                              Tesco\n",
       "5                           Barclays\n",
       "6                        J Sainsbury\n",
       "7                           Unilever\n",
       "8                       Virgin Media\n",
       "9                              Ocado\n",
       "10                              Zopa\n",
       "11  Department for Work And Pensions\n",
       "12                         Accenture\n",
       "13                               IBM\n",
       "14                     HSBC Holdings\n",
       "15                            Capita\n",
       "16                               NHS\n",
       "17                               Sky\n",
       "18                     Deutsche Bank\n",
       "19                            Amazon"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "result_set = soup.find_all(\"div\", class_=\"JobInfoStyle__employerName\")\n",
    "\n",
    "output = np.zeros((len(result_set),1)) \n",
    "output = pd.DataFrame(output)\n",
    "print(output.shape)\n",
    "j = 0\n",
    "for i in result_set:\n",
    "                  output.iloc[j,0] = i.text\n",
    "                  j +=1\n",
    "\n",
    "#       output.iloc[result_set.index(i),j] = k.text\n",
    "                \n",
    "#output[result_set.index(j), \n",
    "\n",
    "# for i, j in enumerate(result_set[4].children):\n",
    "#     print(i, j.text)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = soup.find_all(\"div\", class_=\"rangeValues tbl fill\")\n",
    "for a in aaa:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "salaries[2:salaries.shape[0],:]\n",
    "salaries = salaries[np.arange(1,33,2),:]\n",
    "jtplot.style('monokai')\n",
    "plt.plot(min_sal)\n",
    "plt.plot(max_sal)\n",
    "plt.legend(['min', 'max'], ncol=1, loc='upper left', \n",
    "           columnspacing=1.0, labelspacing=0.0,\n",
    "           handletextpad=0.5, handlelength=1.5,\n",
    "           fancybox=True, shadow=True)\n",
    "plt.title('Data Scientist salaries - London')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "#bckgr colour is #2f2f2f\n",
    "plt.bar(x = salaries[:,2], height = salaries[:,1], width = 1, color = 'orange', alpha = 0.7)\n",
    "plt.bar(x = salaries[:,2], height = salaries[:,0], width = 1, color = '#232323')\n",
    "plt.legend(['range'], ncol=1, loc='upper left', \n",
    "           columnspacing=1.0, labelspacing=0.0,\n",
    "           handletextpad=0.5, handlelength=1.5,\n",
    "           fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
